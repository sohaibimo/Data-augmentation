{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePgZzNdwGcPG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1siD9hsFGkrJ",
        "outputId": "1df63488-dc8d-4a1c-81ee-54d90ef1cbe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa3LHjjOGvd2",
        "outputId": "aa723d7e-a63a-4533-b3a5-dd474ea00ad1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 106ms/step - accuracy: 0.3211 - loss: 1.8411 - val_accuracy: 0.5185 - val_loss: 1.3227\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 94ms/step - accuracy: 0.5279 - loss: 1.3102 - val_accuracy: 0.5812 - val_loss: 1.1824\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 91ms/step - accuracy: 0.6010 - loss: 1.1296 - val_accuracy: 0.6195 - val_loss: 1.0826\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.6424 - loss: 1.0244 - val_accuracy: 0.6450 - val_loss: 0.9962\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.6712 - loss: 0.9436 - val_accuracy: 0.6763 - val_loss: 0.9410\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.6943 - loss: 0.8686 - val_accuracy: 0.6810 - val_loss: 0.9293\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.7046 - loss: 0.8366 - val_accuracy: 0.6950 - val_loss: 0.8843\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 90ms/step - accuracy: 0.7246 - loss: 0.7870 - val_accuracy: 0.6920 - val_loss: 0.8968\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.7366 - loss: 0.7521 - val_accuracy: 0.6954 - val_loss: 0.8909\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 91ms/step - accuracy: 0.7447 - loss: 0.7243 - val_accuracy: 0.7041 - val_loss: 0.8685\n"
          ]
        }
      ],
      "source": [
        "def build_cnn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and train the model without augmentation\n",
        "cnn_model_no_augmentation = build_cnn_model()\n",
        "\n",
        "# Train the model without data augmentation\n",
        "history_no_aug = cnn_model_no_augmentation.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C2zQgsvGzOy",
        "outputId": "d99a7127-3daf-40ad-b1f6-dfc589bd95e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 148ms/step - accuracy: 0.1064 - loss: 2.2995 - val_accuracy: 0.1000 - val_loss: 2.3727\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 146ms/step - accuracy: 0.1086 - loss: 2.2958 - val_accuracy: 0.1005 - val_loss: 2.4352\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 141ms/step - accuracy: 0.1082 - loss: 2.2936 - val_accuracy: 0.1000 - val_loss: 2.3399\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 140ms/step - accuracy: 0.1115 - loss: 2.2917 - val_accuracy: 0.0999 - val_loss: 3.0784\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 145ms/step - accuracy: 0.1122 - loss: 2.2896 - val_accuracy: 0.1013 - val_loss: 2.7091\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 141ms/step - accuracy: 0.1112 - loss: 2.2895 - val_accuracy: 0.1031 - val_loss: 3.6740\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 143ms/step - accuracy: 0.1125 - loss: 2.2913 - val_accuracy: 0.1003 - val_loss: 2.9271\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 149ms/step - accuracy: 0.1100 - loss: 2.2890 - val_accuracy: 0.1001 - val_loss: 2.5766\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 142ms/step - accuracy: 0.1097 - loss: 2.2897 - val_accuracy: 0.1001 - val_loss: 2.9102\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 141ms/step - accuracy: 0.1095 - loss: 2.2894 - val_accuracy: 0.1049 - val_loss: 2.5043\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "# Fit the augmentation generator on the training data\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Build the same CNN model\n",
        "cnn_model_with_augmentation = build_cnn_model()\n",
        "\n",
        "# Train the model with data augmentation\n",
        "history_with_aug = cnn_model_with_augmentation.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
        "                                                   epochs=10,\n",
        "                                                   validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs2kmTK7G12_"
      },
      "outputs": [],
      "source": [
        "# Evaluate the models on the test set\n",
        "test_loss_no_aug, test_acc_no_aug = cnn_model_no_augmentation.evaluate(X_test, y_test)\n",
        "test_loss_with_aug, test_acc_with_aug = cnn_model_with_augmentation.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Model without Augmentation - Test Accuracy: {test_acc_no_aug:.4f}, Test Loss: {test_loss_no_aug:.4f}\")\n",
        "print(f\"Model with Augmentation - Test Accuracy: {test_acc_with_aug:.4f}, Test Loss: {test_loss_with_aug:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRDEufvbG4rF"
      },
      "outputs": [],
      "source": [
        "# Plotting the accuracy and loss for both models\n",
        "def plot_history(history_no_aug, history_with_aug):\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history_no_aug.history['accuracy'], label='Accuracy without Augmentation')\n",
        "    plt.plot(history_with_aug.history['accuracy'], label='Accuracy with Augmentation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history_no_aug.history['loss'], label='Loss without Augmentation')\n",
        "    plt.plot(history_with_aug.history['loss'], label='Loss with Augmentation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_no_aug, history_with_aug)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1nZZ3irG6x9"
      },
      "outputs": [],
      "source": [
        "# Make predictions for both models\n",
        "y_pred_no_aug = cnn_model_no_augmentation.predict(X_test)\n",
        "y_pred_with_aug = cnn_model_with_augmentation.predict(X_test)\n",
        "\n",
        "# Convert predictions from one-hot encoding to label format\n",
        "y_pred_no_aug_labels = np.argmax(y_pred_no_aug, axis=1)\n",
        "y_pred_with_aug_labels = np.argmax(y_pred_with_aug, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion Matrix for model without augmentation\n",
        "cm_no_aug = confusion_matrix(y_true_labels, y_pred_no_aug_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_no_aug, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.title(\"Confusion Matrix without Augmentation\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix for model with augmentation\n",
        "cm_with_aug = confusion_matrix(y_true_labels, y_pred_with_aug_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_with_aug, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.title(\"Confusion Matrix with Augmentation\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}